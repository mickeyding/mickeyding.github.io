![image](https://github.com/user-attachments/assets/70e682fe-6d38-4178-b8d1-8617428b046c)

# 目标

该文章提出了 InternLM-XComposer2.5-OmniLive (IXC2.5-OL)，一个具备长时间多模态（音频和视频）实时交互能力的AI系统
![image](https://github.com/user-attachments/assets/cd4fc1cc-6091-4b80-b4de-1287825aa2af)

# 方法
## **记忆模块利用机制**
为了利用多模态长记忆模块并解决大规模数据的问题，训练过程中引入了**三大核心任务**，针对视频和音频数据的记忆管理：

![image](https://github.com/user-attachments/assets/91e9c192-70f9-44e5-9534-41f9940f6989)



### **1. 视频片段压缩任务**
- **目标**：通过**压缩器**（Compressor）模块，将视频短片段的信息提取并压缩为**短期记忆**和**全局记忆**。  
- **数据处理**：  
   - 使用数据集如 **ActivityNet** 和 **Ego4D**，训练模型对输入视频的短时间片段进行编码。  
   - 通过**特征降采样**和**自动回归模型**，实现信息的有效压缩。

- **示例流程**：  
   - 输入视频特征：
   
   $$ F_k \in \mathbb{R}^{T \times N \times C} $$

   - 输出：  
     - 短期记忆 $ H_k $：保留每个时间片段的详细特征。  
     - 全局记忆 $ \hat{H}_k $：高度压缩的关键特征。

   - 训练目标：最大化短期记忆与全局记忆之间的信息一致性，确保压缩后的记忆保留有用信息。

---

### **2. 记忆整合任务**
- **目标**：将多个短期记忆（视频片段）整合为高效的**长期记忆**，模拟长视频的连续性。  
- **方法**：  
   - 压缩器模块接收多个短期记忆 $ H_1, H_2, \dots, H_k $ 和对应的全局记忆 $ \hat{H}_1, \hat{H}_2, \dots, \hat{H}_k $。  
   - 通过特征聚合，生成长期记忆 $ H̄ $。  

- **关键步骤**：
   - 整合公式：  
   
     $$
     H̄ = \text{Compressor}([H_1 \circ H_2 \circ ... \circ H_k \circ \hat{H}_1 \circ \hat{H}_2 \circ ... \circ \hat{H}_k])
     $$

   - 输出的长期记忆 $ H̄ $ 保留宏观上下文信息，同时压缩了冗余数据。  

- **训练数据**：使用长视频数据，如 **Ego4D** 和 **ActivityNet**，并构建**时间序列任务**来训练模型进行整合。

---

### **3. 视频片段检索任务**
- **目标**：模拟推理时的**记忆检索**，即从长期记忆中找到与用户查询相关的视频片段。  
- **方法**：  
   - **编码查询**：将用户的文本查询编码到记忆特征空间中。  
   - **相似度计算**：通过余弦相似度或其他检索方法，将查询与长期记忆匹配，检索相关的视频片段。  

- **训练数据**：  
   - 使用带有标注的**视频问答数据集**（例如 FunQA、TrafficQA），构建显式和**隐式问题**的训练样本。  
   - **隐式问题**包括：  
     - **语义隐式问题**（如“天气怎么样？” → 需要检索雨伞、雨声等相关片段）。  
     - **引用隐式问题**（如“这是什么？” → 检索当前视频帧）。


