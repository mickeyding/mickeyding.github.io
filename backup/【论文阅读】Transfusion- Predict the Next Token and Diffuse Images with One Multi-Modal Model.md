# Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model

## 具体方案

- 联合多模态损失函数：Transfusion模型将语言建模（next-token prediction）与图像扩散损失相结合，模型在训练过程中同时暴露于这两种不同的模态和相应的损失函数。文本使用语言模型损失（LM Loss），图像使用扩散损失。

- 共享的Transformer架构：该模型使用单一的Transformer架构来处理所有模态，无需离散化图像数据，避免了信息丢失。文本数据通过标准的嵌入层转换为向量，而图像数据则被分割为多个patch向量序列，并使用适合的编码和解码层（例如线性层或U-Net层）进行处理输入到网络。

- 双模态推理机制：在推理时，模型可以根据不同的数据模态进行转换，文本数据采用逐词生成方式，而图像数据则使用标准的扩散模型生成。通过这种方法，模型能够在同一个任务中灵活处理文本和图像的生成和理解。

- 注意力机制的调整：模型结合了两种注意力机制——文本部分采用自回归的因果注意力机制，而图像部分则使用双向注意力，使得图像中的各个patch能够彼此交互。这种机制提升了图像生成任务中的性能。

- 扩展规模以提高性能：Transfusion模型通过扩大模型参数和训练数据的规模，能够在跨模态任务中展现出显著的性能提升。实验表明，扩大到7B参数并训练超过2T多模态数据后，模型在生成图像和文本方面的表现与其他单一模态模型相媲美。

## 共享表示空间
Transfusion的一个贡献就是利用共享表示空间提升多模态任务的表现；“共享表示空间”是指模型通过将不同模态（例如文本和图像）的输入数据转换为相同格式的向量表示（即嵌入），并在相同的模型框架内处理它们。这意味着文本和图像数据在同一个模型的相同层级上进行处理，并共享同一个特征空间或表示空间。这种设计使得模型能够理解并生成跨模态的语义关联。

### 共享表示空间如何理解？

**数据转化为统一的向量表示**:
文本模态：文本输入首先通过嵌入层（embedding layer）转化为向量。每个单词都会被转换成一个固定长度的向量表示，表示它的语义特征。
图像模态：图像被切分为多个patch（图像块），然后将每个patch转化为与文本类似的向量表示。图像的这些局部块被视为一系列向量序列，像处理文本序列一样被处理。

**共享的特征空间**：
一旦文本和图像都被转化为向量形式，它们就可以在同一空间中被表示和处理。共享表示空间的关键在于，模型可以对文本和图像使用相同的编码器（例如Transformer），以统一的方式处理不同模态的数据。这种设计具有以下优势：

模态融合：模型可以将来自文本和图像的特征融合在一起，从而生成跨模态的语义关联。例如，模型可以从图像中提取信息，并结合文本生成描述性的句子。
多模态理解：由于文本和图像的表示在相同的空间中，模型能够更好地理解两者之间的关系。例如，模型可以通过处理图像特征来回答基于视觉问题的问答任务，或生成图像的文本描述。

**处理不同模态的灵活性**
在共享表示空间中，模型能够灵活处理纯文本、纯图像或文本与图像混合的任务。共享表示空间确保模型能够根据输入数据在不同任务之间进行转换

**跨模态任务的语义对齐**：
共享表示空间使得文本和图像在语义上能够对齐。这意味着模型可以理解文本中的语义，并将其映射到与图像对应的表示。反之亦然，模型可以从图像特征中提取出对应的文本信息。这种对齐使得模型能够执行跨模态任务

### 共享表示空间的优势

- 减少模态隔离：传统的多模态模型往往为不同模态单独训练子网络或子模型，增加了模型的复杂性。共享表示空间消除了这种隔离，使得文本和图像可以在同一框架下处理，简化了模型的设计。
- 跨模态任务表现更好：由于文本和图像都共享相同的表示空间，模型更容易生成跨模态的高质量输出；而将所有模态对齐到文本空间可能在某些特定场景下损失部分细节，尤其是在需要高精度的图像生成任务中，在一些任务中，图像对文本空间的过度对齐可能会导致图像特征的部分损失，影响图像生成的细节；

## 任务表现
最好的配置下（7B），最多的数据下（2Ttokens），图像生成的质量和SDXL（2.6B）差不多；比show-o的FID要低；
但是全文比较的其他工作有限，基础配置下只和Chameleon模型比较；

**文本生成任务**：Transfusion比Chameleon模型表现更好，尤其在参数较少时，Transfusion使用的FLOPs显著减少。

**图像生成任务**：对比模型：Transfusion在图像生成中表现显著优于Chameleon，尤其是在计算效率上。Transfusion在图像生成任务中的FLOP效率约为Chameleon的34倍。同时，Transfusion生成的图像质量与其他领先的图像生成模型（如DeepFloyd和DALL-E 2）相当，且支持同时生成文本和图像。

**视觉问答（VQA）**：
Transfusion能够有效处理视觉问答任务，结合文本和图像的表示空间生成准确的答案。在与Chameleon对比中，Transfusion通过其高效的扩散模型提升了回答问题的精度。
