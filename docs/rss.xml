<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>NiaDing's Technical Blog </title><link>https://mickeyding.github.io</link><description>I have research and development experience in autonomous driving simulation, and have explored related technologies such as NeRF, 3DGS and diffusion. Here, I will be sharing my insights and knowledge with everyone.</description><copyright>NiaDing's Technical Blog </copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://mickeyding.github.io</link></image><lastBuildDate>Thu, 19 Sep 2024 08:53:42 +0000</lastBuildDate><managingEditor>NiaDing's Technical Blog </managingEditor><ttl>60</ttl><webMaster>NiaDing's Technical Blog </webMaster><item><title>【论文阅读】Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model</title><link>https://mickeyding.github.io/post/%E3%80%90-lun-wen-yue-du-%E3%80%91Transfusion-%20Predict%20the%20Next%20Token%20and%20Diffuse%20Images%20with%20One%20Multi-Modal%20Model.html</link><description># Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model&#13;
&#13;
## 具体方案&#13;
&#13;
- 联合多模态损失函数：Transfusion模型将语言建模（next-token prediction）与图像扩散损失相结合，模型在训练过程中同时暴露于这两种不同的模态和相应的损失函数。</description><guid isPermaLink="true">https://mickeyding.github.io/post/%E3%80%90-lun-wen-yue-du-%E3%80%91Transfusion-%20Predict%20the%20Next%20Token%20and%20Diffuse%20Images%20with%20One%20Multi-Modal%20Model.html</guid><pubDate>Thu, 19 Sep 2024 08:26:27 +0000</pubDate></item><item><title>【论文阅读】Show-o: ONE SINGLE TRANSFORMER TO UNIFY MULTIMODAL UNDERSTANDING AND GENERATION</title><link>https://mickeyding.github.io/post/%E3%80%90-lun-wen-yue-du-%E3%80%91Show-o-%20ONE%20SINGLE%20TRANSFORMER%20TO%20UNIFY%20MULTIMODAL%20UNDERSTANDING%20AND%20GENERATION.html</link><description># Show-o: ONE SINGLE TRANSFORMER TO UNIFY MULTIMODAL UNDERSTANDING AND GENERATION&#13;
&#13;
SHOW-O 通过一个单一的Transformer架构，引入**离散去噪过程**处理图像的生成任务，LLM任务采用因果attention，图像生成任务采用全局attention，统一了多模态理解和生成任务，无需多个专门的模型。</description><guid isPermaLink="true">https://mickeyding.github.io/post/%E3%80%90-lun-wen-yue-du-%E3%80%91Show-o-%20ONE%20SINGLE%20TRANSFORMER%20TO%20UNIFY%20MULTIMODAL%20UNDERSTANDING%20AND%20GENERATION.html</guid><pubDate>Wed, 18 Sep 2024 04:27:35 +0000</pubDate></item><item><title>StableDiffusion3代码分析</title><link>https://mickeyding.github.io/post/StableDiffusion3-dai-ma-fen-xi.html</link><description># StableDiffusion3Pipeline&#13;
## 步骤和算法&#13;
**输入检查：**&#13;
调用 [check_inputs]方法，验证输入参数的有效性。</description><guid isPermaLink="true">https://mickeyding.github.io/post/StableDiffusion3-dai-ma-fen-xi.html</guid><pubDate>Sat, 14 Sep 2024 02:17:54 +0000</pubDate></item></channel></rss>